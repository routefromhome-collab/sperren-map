import aiohttp
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote
import pandas as pd
from telegram.ext import Application
from datetime import datetime, timedelta
import re
import os
import sys
import json
import random
from collections import defaultdict
import time
from tqdm.asyncio import tqdm_asyncio
from tqdm import tqdm
import subprocess
import folium
from geopy.geocoders import Nominatim
import logging
from telegram.error import RetryAfter, TelegramError
import html
import math
from geopy.extra.rate_limiter import RateLimiter as GeoRateLimiter
# ------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏/–∫–æ–Ω—Ñ–∏–≥ -------
print(os.getcwd())

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')  # GitHub PAT (optional)
CACHE_FILE = 'cache.json'

MAX_CONCURRENT_REQUESTS = 60  # –º–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å/–ø–æ–Ω–∏–∑–∏—Ç—å
RATE_LIMIT_DELAY = 0.01
PROGRESS_UPDATE_EVERY = 50  # –æ–±–Ω–æ–≤–ª—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ç–µ–ª–µ–≥–µ –∫–∞–∂–¥—ã–µ N —É–ª–∏—Ü
TELEGRAM_CHUNK_MAX = 4000  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è

GEOCODE_TIMEOUT = 10
USER_AGENT = "sperren_route_optimizer"
MAX_POINTS = 300  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –ø–æ —É—Å–ª–æ–≤–∏—é
GOOGLE_CHUNK = 20  # Google Maps waypoints per link


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def haversine_km(a, b):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º) –º–µ–∂–¥—É –ø–∞—Ä–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç a=(lat,lon), b=(lat,lon)."""
    lat1, lon1 = math.radians(a[0]), math.radians(a[1])
    lat2, lon2 = math.radians(b[0]), math.radians(b[1])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    R = 6371.0088
    sa = math.sin(
        dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2
    return 2 * R * math.asin(math.sqrt(sa))


def geocode_addresses(addresses, city=None, pause=1.0):
    """
        –ì–µ–æ–∫–æ–¥–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {address: (lat,lon)}.
        - addresses: —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–º–æ–∂–Ω–æ –¥–æ 300)
        - city: –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –∑–∞–ø—Ä–æ—Å—É (–Ω–∞–ø—Ä–∏–º–µ—Ä 'Wuppertal')
        - pause: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ Nominatim
        """
    geolocator = Nominatim(user_agent=USER_AGENT,
                           timeout=GEOCODE_TIMEOUT)  # type: ignore
    geocode = GeoRateLimiter(geolocator.geocode, min_delay_seconds=pause)

    coords = {}
    for addr in addresses:
        query = f"{addr}, {city}" if city else addr
        try:
            loc = geocode(query)
            if loc:
                coords[addr] = (loc.latitude, loc.longitude)
            else:
                coords[addr] = None
        except Exception as e:
            logger.warning("Geocode failed for '%s': %s", addr, e)
            coords[addr] = None

        # –Ω–µ–±–æ–ª—å—à–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è —É–≤–∞–∂–µ–Ω–∏—è Nominatim
        time.sleep(random.uniform(0.2, 0.6))

    return coords


def build_distance_matrix(coord_list):
    """coord_list: list of (lat,lon). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (km)."""
    n = len(coord_list)
    mat = [[0.0] * n for _ in range(n)]
    for i in range(n):
        for j in range(i + 1, n):
            d = haversine_km(coord_list[i], coord_list[j])
            mat[i][j] = d
            mat[j][i] = d
    return mat


# --- TSP: nearest neighbor + 2-opt ---
def nearest_neighbor_tsp(dist_mat, start_index=0):
    n = len(dist_mat)
    visited = [False] * n
    route = [start_index]
    visited[start_index] = True
    for _ in range(n - 1):
        last = route[-1]
        # –≤—ã–±—Ä–∞—Ç—å –±–ª–∏–∂–∞–π—à—É—é –Ω–µ –ø–æ—Å–µ—â—ë–Ω–Ω—É—é
        best = None
        bestd = float('inf')
        for j in range(n):
            if not visited[j] and dist_mat[last][j] < bestd:
                bestd = dist_mat[last][j]
                best = j
        if best is None:
            break
        route.append(best)
        visited[best] = True
    return route


def two_opt(route, dist_mat, improvement_threshold=0.0001):
    """
    –£–ª—É—á—à–µ–Ω–∏–µ 2-opt. route ‚Äî —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤.
    """
    n = len(route)
    if n < 4:
        return route
    improved = True
    while improved:
        improved = False
        for i in range(1, n - 2):
            for j in range(i + 1, n):
                if j - i == 1:  # —Å–æ—Å–µ–¥–Ω–∏–µ, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                    continue
                a, b = route[i - 1], route[i]
                c, d = route[j - 1], route[j % n]
                delta = dist_mat[a][c] + dist_mat[b][d] - dist_mat[a][
                    b] - dist_mat[c][d]
                if delta < -improvement_threshold:
                    # invert
                    route[i:j] = reversed(route[i:j])
                    improved = True
        # –º–æ–∂–Ω–æ –≤—ã–π—Ç–∏, –µ—Å–ª–∏ –Ω–µ —É–ª—É—á—à–∏–ª–æ—Å—å
    return route


USER_AGENTS = [
    # –Ω–µ—Å–∫–æ–ª—å–∫–æ user-agents –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
]

# –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ------- –£—Ç–∏–ª–∏—Ç—ã -------
def get_random_headers():
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept":
        "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "Connection": "keep-alive",
    }


def normalize_street_name(name: str) -> str:
    name = name.lower().strip()
    name = re.sub(r'\bstr\b\.?$', 'stra√üe', name)
    name = re.sub(r'str\.$', 'stra√üe', name)
    name = re.sub(r'str$', 'stra√üe', name)
    name = name.replace('strasse', 'stra√üe')
    return name


def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_cache(cache):
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


def chunk_text(text, max_len=TELEGRAM_CHUNK_MAX):
    chunks = []
    while len(text) > max_len:
        # try split at newline
        split_at = text.rfind('\n', 0, max_len)
        if split_at == -1:
            split_at = max_len
        chunks.append(text[:split_at])
        text = text[split_at:].lstrip('\n')
    if text:
        chunks.append(text)
    return chunks


def group_addresses_by_street(addresses):
    grouped = defaultdict(list)
    for addr in addresses:
        # –µ—Å–ª–∏ –∞–¥—Ä–µ—Å –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —á–∏—Å–ª–æ –∏–ª–∏ —á–∏—Å–ª–æ+–±—É–∫–≤—É ‚Üí –µ—Å—Ç—å –¥–æ–º
        m = re.match(r"^(.*?)[\s]+(\d+[a-zA-Z]?)$", addr.strip())
        if m:
            street = m.group(1).strip()
            house = m.group(2).strip()
            grouped[street].append(house)
        else:
            # –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏–µ —É–ª–∏—Ü—ã
            grouped[addr.strip()] = []

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–æ–º–∞–º –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
    def house_key(h):
        m = re.match(r"(\d+)(.*)", h)
        if m:
            return (int(m.group(1)), m.group(2))
        return (10**9, h)

    for s in grouped:
        grouped[s] = sorted(set(grouped[s]), key=house_key)

    return grouped


def generate_google_maps_route_links(ordered_addresses,
                                     city,
                                     chunk_size=GOOGLE_CHUNK):
    """
        ordered_addresses: list –∞–¥—Ä–µ—Å–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (—Å—Ç—Ä–æ–∫–∏)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ Google Maps; –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç <= chunk_size —Ç–æ—á–µ–∫.
        –§–æ—Ä–º–∞—Ç: https://www.google.com/maps/dir/{A}/{B}/{C}/
        (–∏—Å–ø–æ–ª—å–∑—É–µ–º url-encoded –∞–¥—Ä–µ—Å—ã)
        """
    links = []
    # Google –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç origin/destination/waypoints; –ø—Ä–æ—â–µ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /dir/A/B/C/...
    i = 0
    while i < len(ordered_addresses):
        segment = ordered_addresses[i:i + chunk_size]
        encoded = [quote(f"{s}, {city}") for s in segment]
        route_url = "https://www.google.com/maps/dir/" + "/".join(
            encoded) + "/"
        links.append(route_url)
        i += chunk_size
    return links


    # --- –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç ---
def build_optimal_route(addresses_with_houses,
                        start_coords=None,
                        city=None,
                        geocode_pause=1.0):
    """
        addresses_with_houses: —Å–ø–∏—Å–æ–∫ –ø–æ–ª–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ (—Å—Ç—Ä–æ–∫) ‚Äî —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å (–¥–æ 300).
        start_coords:
            - –µ—Å–ª–∏ tuple(lat,lon) ‚Äî –º–∞—Ä—à—Ä—É—Ç –Ω–∞—á–Ω—ë—Ç—Å—è –ò–ó —ç—Ç–æ–π —Ç–æ—á–∫–∏
            - –µ—Å–ª–∏ None ‚Äî –º–∞—Ä—à—Ä—É—Ç –Ω–∞—á–Ω—ë—Ç—Å—è –° –ü–ï–†–í–û–ô –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–æ—á–∫–∏
        city: –≥–æ—Ä–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä "Wuppertal")
        geocode_pause: –ø–∞—É–∑–∞ –º–µ–∂–¥—É –≥–µ–æ–∫–æ–¥–∞–º–∏
        """

    if len(addresses_with_houses) == 0:
        return [], [], {}

    if len(addresses_with_houses) > MAX_POINTS:
        raise ValueError(
            f"Too many points: {len(addresses_with_houses)} > {MAX_POINTS}")

    # 1) –ì–µ–æ–∫–æ–¥–∏—Ä—É–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞
    coords_map = geocode_addresses(addresses_with_houses,
                                   city=city,
                                   pause=geocode_pause)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –Ω–∞—à–ª–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    found_items = [a for a in addresses_with_houses if coords_map.get(a)]
    if not found_items:
        # –Ω–∏—á–µ–≥–æ –Ω–µ –≥–µ–æ–∫–æ–¥–∏—Ä—É–µ—Ç—Å—è ‚Äî –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        return addresses_with_houses, [], coords_map

    coord_list = [coords_map[a] for a in found_items]

    added_start = False
    start_index = 0

    # ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º:
    # –µ—Å–ª–∏ start_coords –µ—Å—Ç—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –Ω–∞—á–∞–ª–æ
    # –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π –∞–¥—Ä–µ—Å–Ω–æ–π —Ç–æ—á–∫–∏, –Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–º–∞–µ—Ç—Å—è
    if start_coords:
        coord_list = [start_coords] + coord_list
        found_items = ["__START__"] + found_items
        added_start = True
        start_index = 0
    else:
        start_index = 0  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞ —Å–ø–∏—Å–∫–∞

    # –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
    dist_mat = build_distance_matrix(coord_list)

    # –ë–∞–∑–æ–≤—ã–π TSP + —É–ª—É—á—à–µ–Ω–∏–µ
    initial_route = nearest_neighbor_tsp(dist_mat, start_index=start_index)
    improved = two_opt(initial_route[:], dist_mat)

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤
    ordered = [found_items[i] for i in improved]

    # –ï—Å–ª–∏ –±—ã–ª –ø—Å–µ–≤–¥–æ-—Å—Ç–∞—Ä—Ç __START__, —É–±–∏—Ä–∞–µ–º –º–µ—Ç–∫—É
    if added_start:
        if ordered and ordered[0] == "__START__":
            ordered = ordered[1:]

    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤
    final_addresses = []
    for a in ordered:
        if a != "__START__":
            final_addresses.append(a)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Google Maps —Å—Å—ã–ª–æ–∫
    route_links = []
    if start_coords:
        # —Å—Ç–∞—Ä—Ç ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        all_points = [f"{start_coords[0]},{start_coords[1]}"
                      ] + [f"{a}, {city}" for a in final_addresses]
        i = 0
        while i < len(all_points):
            seg = all_points[i:i + GOOGLE_CHUNK]
            encoded = [quote(s) for s in seg]
            route_links.append("https://www.google.com/maps/dir/" +
                               "/".join(encoded) + "/")
            i += GOOGLE_CHUNK
    else:
        # —Å—Ç–∞—Ä—Ç ‚Äî –ø–µ—Ä–≤–∞—è –∞–¥—Ä–µ—Å–Ω–∞—è —Ç–æ—á–∫–∞
        route_links = generate_google_maps_route_links(final_addresses,
                                                       city,
                                                       chunk_size=GOOGLE_CHUNK)

    return final_addresses, route_links, coords_map


# ------- Rate limiter –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å -------
class RateLimiter:

    def __init__(self, delay):
        self.delay = delay
        self.last_request = 0

    async def acquire(self):
        current = time.time()
        diff = current - self.last_request
        if diff < self.delay:
            await asyncio.sleep(self.delay - diff)
        self.last_request = time.time()


async def safe_request(session, method, url, rate_limiter, **kwargs):
    retries = 5
    for attempt in range(retries):
        try:
            await rate_limiter.acquire()
            headers = kwargs.pop('headers', None) or get_random_headers()
            async with session.request(method, url, headers=headers,
                                       **kwargs) as response:
                if response.status in (429, ) or response.status >= 500:
                    wait = min(2**attempt + random.random(), 30)
                    logger.warning("HTTP %s from %s ‚Äî wait %.1fs",
                                   response.status, url, wait)
                    await asyncio.sleep(wait)
                    continue
                return await response.text()
        except Exception as e:
            wait = min(2**attempt + random.random(), 30)
            logger.warning("Request error %s -> waiting %.1fs", e, wait)
            await asyncio.sleep(wait)
    logger.error("Failed to get %s after %d attempts", url, retries)
    return None


# ------- Telegram helper with RetryAfter handling (HTML parse_mode) -------
async def tg_send(bot, method='send_message', **kwargs):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞: –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç RetryAfter.
    method: 'send_message' or 'send_photo' etc. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é send_message.
    kwargs ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–∑–æ–≤–∞ –º–µ—Ç–æ–¥–∞.
    """
    max_attempts = 6
    for attempt in range(max_attempts):
        try:
            if method == 'send_message':
                return await bot.send_message(**kwargs)
            else:
                # –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                return await getattr(bot, method)(**kwargs)
        except RetryAfter as e:
            wait = e.retry_after + 1
            logger.warning("Telegram RetryAfter: wait %s s", wait)
            await asyncio.sleep(wait)
        except TelegramError as e:
            logger.warning("TelegramError: %s (attempt %d/%d)", e, attempt + 1,
                           max_attempts)
            await asyncio.sleep(min(2**attempt, 30))
        except Exception as e:
            logger.exception("Unexpected Telegram exception: %s", e)
            await asyncio.sleep(min(2**attempt, 30))
    logger.error("Failed to send telegram message after retries.")
    return None


# ------- –ü–∞—Ä—Å–µ—Ä –æ–¥–Ω–æ–π —É–ª–∏—Ü—ã -------
async def fetch_and_parse(session, url, data, street, current_month,
                          current_day, semaphore, cache, rate_limiter):
    async with semaphore:
        key = f"{street}__{current_month}__{current_day}"
        if key in cache:
            return cache[key]
        text = await safe_request(session,
                                  "POST",
                                  url,
                                  rate_limiter,
                                  data=data,
                                  timeout=aiohttp.ClientTimeout(total=25))
        if not text:
            cache[key] = None
            return None

        soup = BeautifulSoup(text, 'lxml')
        month_divs = soup.find_all('div', class_='month')
        page_text = soup.get_text(" ", strip=True)
        is_calendar = any(div.find('td') for div in month_divs)
        found_addresses = []

        # —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤—ã–±–æ—Ä–æ–º –¥–æ–º–æ–≤
        if "Auf dieser Stra√üe gibt es mehrere Abfallkalender" in page_text:
            house_links = soup.select('a[href*="streetname"]')
            for link in house_links:
                house_number = link.get_text(strip=True)
                if not house_number:
                    continue
                full_link = urljoin(url, link.get('href'))
                house_text = await safe_request(
                    session,
                    "GET",
                    full_link,
                    rate_limiter,
                    timeout=aiohttp.ClientTimeout(total=15))
                if not house_text:
                    continue
                house_soup = BeautifulSoup(house_text, 'lxml')
                for month_div in house_soup.find_all('div', class_='month'):
                    header = month_div.find(['h3', 'span'])
                    if not header:
                        continue
                    if header.get_text(strip=True) != current_month:
                        continue
                    for td in month_div.find_all(
                            'td', class_=['', 'holiday', 'exception']):
                        day_text = ''.join(re.findall(r'\d+', td.get_text()))
                        if day_text == current_day and td.find(
                                "i", title="Sperrm√ºll"):
                            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å "Street Name house"
                            found_addresses.append(f"{street} {house_number}")

        # –µ—Å–ª–∏ —Å—Ä–∞–∑—É –∫–∞–ª–µ–Ω–¥–∞—Ä—å –¥–ª—è –≤—Å–µ–π —É–ª–∏—Ü—ã
        elif is_calendar:
            for month_div in month_divs:
                header = month_div.find(['h3', 'span'])
                if not header:
                    continue
                if header.get_text(strip=True) != current_month:
                    continue
                for td in month_div.find_all(
                        'td', class_=['', 'holiday', 'exception']):
                    day_text = ''.join(re.findall(r'\d+', td.get_text()))
                    if day_text == current_day and td.find("i",
                                                           title="Sperrm√ºll"):
                        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–ª—É—é —É–ª–∏—Ü—É
                        found_addresses.append(street)
        else:
            # –∏—â–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ—Ö–æ–∂–∏—Ö —É–ª–∏—Ü
            similar_links = soup.select('a[href*="streetname"]')
            for link in similar_links:
                street_text = link.get_text(strip=True)

                # —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –æ—à–∏–±–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
                if normalize_street_name(street_text) == normalize_street_name(
                        street):
                    full_link = urljoin(url, link.get('href'))

                    # —Å–∫–∞—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ä–µ–∞–ª—å–Ω–æ–π —É–ª–∏—Ü–µ–π
                    exact_page = await safe_request(
                        session,
                        "GET",
                        full_link,
                        rate_limiter,
                        timeout=aiohttp.ClientTimeout(total=15))

                    if not exact_page:
                        continue

                    exact_soup = BeautifulSoup(exact_page, 'lxml')

                    # –ø–æ–≤—Ç–æ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                    for month_div in exact_soup.find_all('div',
                                                         class_='month'):
                        header = month_div.find(['h3', 'span'])
                        if not header:
                            continue
                        if header.get_text(strip=True) != current_month:
                            continue
                        for td in month_div.find_all(
                                'td', class_=['', 'holiday', 'exception']):
                            day_text = ''.join(
                                re.findall(r'\d+', td.get_text()))
                            if day_text == current_day and td.find(
                                    "i", title="Sperrm√ºll"):
                                found_addresses.append(street)
        cache[key] = found_addresses if found_addresses else None

        return cache[key]


# ------- –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã (–≤–∫–ª—é—á–∞–µ–º –í–°–ï –∞–¥—Ä–µ—Å–∞) –∏ –ø—É—à –≤ Git (–∞–∫–∫—É—Ä–∞—Ç–Ω–æ) -------


def create_map_and_push(addresses, city, filename="map.html"):
    """
        –°–æ–∑–¥–∞—ë—Ç –∫–∞—Ä—Ç—É:
          - –º–∞—Ä–∫–µ—Ä—ã –¥–æ–º–æ–≤ (Nominatim)
          - —Å–æ–±–∏—Ä–∞–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é —É–ª–∏—Ü —á–µ—Ä–µ–∑ Overpass (–Ω–µ —Ä–∏—Å—É–µ—Ç –∑–∞—Ä–∞–Ω–µ–µ)
          - –∫–Ω–æ–ø–∫–∞ "–ü–æ–∫–∞–∑–∞—Ç—å –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É –∫–æ –º–Ω–µ" (–Ω–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à—É—é —Ç–æ—á–∫—É –Ω–∞ –ø–æ–ª–∏–ª–∏–Ω–∏–∏,
            –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç popup —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º (–º) –∏ –ø—Ä–∏–º–µ—Ä–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –ø–µ—à–∫–æ–º)
          - –ø–ª–∞–≤–∞—é—â–∞—è —Ä–µ–∫–ª–∞–º–Ω–∞—è –ø–ª–∞—à–∫–∞ —Å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º –¥–∏–∑–∞–π–Ω–æ–º (–º–æ–∂–Ω–æ –∑–∞–∫—Ä—ã—Ç—å)
          - –ø—É—à –≤ GitHub Pages, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω GITHUB_TOKEN
        –í–∞–∂–Ω–æ: JS-—à–∞–±–ª–æ–Ω –≤—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –±–µ–∑–æ–ø–∞—Å–Ω–æ (—á–µ—Ä–µ–∑ –º–∞—Ä–∫–µ—Ä—ã), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å { } –≤ f-—Å—Ç—Ä–æ–∫–∞—Ö.
        """
    import os
    import json
    import logging
    import subprocess
    import requests
    import folium
    import re
    from datetime import datetime
    from geopy.geocoders import Nominatim
    from geopy.extra.rate_limiter import RateLimiter
    from folium.plugins import LocateControl
    from typing import Optional

    logger = logging.getLogger("MAP")
    logger.setLevel(logging.INFO)

    # –ù–µ–±–æ–ª—å—à–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–ø—Ä–∏–º–µ—Ä). –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–¥—Å—Ç–∞–≤—å —Å–≤–æ—é normalize_street_name
    def normalize_street_name(name: Optional[str]) -> Optional[str]:
        if not name:
            return None
        s = name.strip()
        # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –ª–æ–≥–∏–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è)
        s = re.sub(r'\s+', ' ', s)
        return s

    # –≥–µ–æ–∫–æ–¥–µ—Ä
    geolocator = Nominatim(user_agent="sperren_map_streets")
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    fmap = folium.Map(location=[51.2562, 7.1508], zoom_start=12)

    geocoded_points = []
    geocoded_info = []
    street_names_from_addresses = set()
    street_geometries = []

    # 1) –ò–∑–≤–ª–µ—á—ë–º –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –∏–º–µ–Ω–∞ —É–ª–∏—Ü –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤
    for addr in addresses:
        if not isinstance(addr, str):
            continue
        m = re.match(r"^(.*\D)\s+(\d[\dA-Za-z/-]*)\s*$", addr.strip())
        street_raw = (m.group(1).strip() if m else addr.strip())
        st = normalize_street_name(street_raw)
        if st:
            street_names_from_addresses.add(st)

    # 2) –ì–µ–æ–∫–æ–¥–∏—Ä—É–µ–º –∞–¥—Ä–µ—Å–∞, —Å—Ç–∞–≤–∏–º –º–∞—Ä–∫–µ—Ä—ã –∏ –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –∏–º—è —É–ª–∏—Ü—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞ Nominatim (–µ—Å–ª–∏ –µ—Å—Ç—å)
    for addr in addresses:
        try:
            q = f"{addr}, {city}" if city else addr
            loc = geocode(q)
            if not loc:
                continue
            lat, lon = float(loc.latitude), float(loc.longitude)
            geocoded_points.append([lat, lon])
            folium.Marker([lat, lon], popup=addr).add_to(fmap)

            street_from_loc = loc.raw.get("address", {}).get("road")
            geocoded_info.append({
                "address": addr,
                "lat": lat,
                "lon": lon,
                "street": street_from_loc
            })
            if street_from_loc:
                street_names_from_addresses.add(
                    normalize_street_name(street_from_loc))
        except Exception:
            # –Ω–µ –ª–æ–º–∞–µ–º –≤—Å—ë –∏–∑-–∑–∞ –æ–¥–Ω–æ–≥–æ –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ –≥–µ–æ–∫–æ–¥–∞
            continue

    if geocoded_points:
        fmap.fit_bounds(geocoded_points)

    # Overpass helper ‚Äî –±–µ—Ä—ë–º –≥–µ–æ–º–µ—Ç—Ä–∏—é —É–ª–∏—Ü—ã, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
    def overpass_query_for_street(name, city_name, timeout=25):
        q = f"""
            [out:json][timeout:{timeout}];
            area["name"="{city_name}"]->.a;
            (
              way["name"="{name}"](area.a);
              relation["name"="{name}"](area.a);
            );
            out geom;
            """
        try:
            r = requests.post("https://overpass-api.de/api/interpreter",
                              data=q.encode("utf-8"),
                              timeout=timeout)
            if r.status_code == 200:
                return r.json()
        except Exception:
            pass
        return None

    # 3) –°–æ–±–∏—Ä–∞–µ–º –≥–µ–æ–º–µ—Ç—Ä–∏–∏ (coords) –¥–ª—è –∫–∞–∂–¥–æ–π —É–ª–∏—Ü—ã (–Ω–µ —Ä–∏—Å—É–µ–º –∏—Ö)
    for street in sorted(street_names_from_addresses):
        try:
            data = overpass_query_for_street(street, city)
            coords_all = []
            if data and isinstance(data, dict) and data.get("elements"):
                for el in data["elements"]:
                    geom = el.get("geometry")
                    if not geom:
                        continue
                    seg = [[float(p["lat"]), float(p["lon"])] for p in geom]
                    if seg:
                        coords_all.extend(seg)
            if coords_all:
                # downsample –ø—Ä–∏ –∏–∑–±—ã—Ç–æ—á–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ç–æ—á–µ–∫
                MAX_POINTS = 2000
                if len(coords_all) > MAX_POINTS:
                    step = max(1, len(coords_all) // MAX_POINTS)
                    coords_all = coords_all[::step]
                street_geometries.append({
                    "name": street,
                    "coords": coords_all
                })
        except Exception:
            continue

    # fallback: –µ—Å–ª–∏ –Ω–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã street->coordinate –∏–∑ geocoded_info
    if not street_geometries:
        names_seen = set()
        for gi in geocoded_info:
            nm = normalize_street_name(gi.get("street") or gi.get("address"))
            if not nm or nm in names_seen:
                continue
            names_seen.add(nm)
            street_geometries.append({
                "name": nm,
                "coords": [[gi["lat"], gi["lon"]]]
            })

        # –∫—Ä–∞–π–Ω–∏–π fallback ‚Äî –ø—Ä–æ—Å—Ç–æ —Ç–æ—á–∫–∏ –¥–æ–º–æ–≤
        if not street_geometries and geocoded_points:
            for i, p in enumerate(geocoded_points):
                street_geometries.append({"name": f"point_{i}", "coords": [p]})

    # LocateControl
    try:
        LocateControl(auto_start=False).add_to(fmap)
    except Exception:
        pass

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ä—Ç—É
    fmap.save(filename)

    # —á–∏—Ç–∞–µ–º html –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º JS –≤—Å—Ç–∞–≤–∫—É –±–µ–∑–æ–ø–∞—Å–Ω–æ
    with open(filename, "r", encoding="utf-8") as fh:
        html_text = fh.read()

    found = re.findall(r"var (\w+) = L\.map", html_text)
    map_var = found[0] if found else None

    # –±–µ–∑–æ–ø–∞—Å–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —É–ª–∏—Ü (—ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º "</")
    streets_json = json.dumps(street_geometries,
                              ensure_ascii=False).replace("</", "<\\/")

    # JS-—à–∞–±–ª–æ–Ω —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏ <<<MAP>>> –∏ <<<STREETS>>> (–Ω–∏–∫–∞–∫–∏—Ö f-—Å—Ç—Ä–æ–∫ —Å JS-—Å–∫–æ–±–∫–∞–º–∏)
    js_template = """
        <script>
        document.addEventListener("DOMContentLoaded", function() {
            try {
                // MAP placeholder
                var MAP = <<<MAP>>>;
                if (!MAP) {
                    // fallback: –Ω–∞–π—Ç–∏ –ª—é–±–æ–π –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ L.Map –≤ window
                    MAP = Object.values(window).find(function(v){ return v && v._leaflet_id && (v instanceof L.Map); });
                }
                if (!MAP) {
                    console.error("Map object not found");
                    return;
                }

                var STREETS = JSON.parse('<<<STREETS>>>');

                function haversine_m(a,b) {
                    var R = 6371000;
                    var œÜ1 = a[0]*Math.PI/180, œÜ2 = b[0]*Math.PI/180;
                    var dœÜ = (b[0]-a[0])*Math.PI/180;
                    var dŒª = (b[1]-a[1])*Math.PI/180;
                    var sa = Math.sin(dœÜ/2)*Math.sin(dœÜ/2) + Math.cos(œÜ1)*Math.cos(œÜ2)*Math.sin(dŒª/2)*Math.sin(dŒª/2);
                    var c = 2*Math.atan2(Math.sqrt(sa), Math.sqrt(1-sa));
                    return R*c;
                }

                function closestPointOnSegment(p, a, b) {
                    var latScale = Math.cos(p[0]*Math.PI/180);
                    var ax=a[0], ay=a[1]*latScale;
                    var bx=b[0], by=b[1]*latScale;
                    var px=p[0], py=p[1]*latScale;
                    var vx=bx-ax, vy=by-ay;
                    var wx=px-ax, wy=py-ay;
                    var vlen2 = vx*vx + vy*vy;
                    if (!vlen2) return a.slice();
                    var t = Math.max(0, Math.min(1, (vx*wx + vy*wy)/vlen2));
                    var cx = ax + vx*t, cy = ay + vy*t;
                    return [cx, cy/latScale];
                }

                function nearestPointOnPolyline(p, coords) {
                    if (!coords || coords.length === 0) return null;
                    if (coords.length === 1) return {point: coords[0], dist: haversine_m(p, coords[0])};
                    var best = null, bestDist = Infinity;
                    for (var i=0;i<coords.length-1;i++){
                        var a = coords[i], b = coords[i+1];
                        var c = closestPointOnSegment(p, a, b);
                        var d = haversine_m(p, c);
                        if (d < bestDist) { bestDist = d; best = {point: c, dist: d}; }
                    }
                    return best;
                }

                function showNearestStreet() {
                    if (!navigator.geolocation) { alert("–ì–µ–æ–ª–æ–∫–∞—Ü–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"); return; }
                    navigator.geolocation.getCurrentPosition(function(pos) {
                        var user = [pos.coords.latitude, pos.coords.longitude];
                        var bestStreet = null, bestInfo = null;

                        for (var si=0; si<STREETS.length; si++) {
                            var st = STREETS[si];
                            var coords = st.coords || [];
                            if (!coords || coords.length === 0) continue;
                            // flatten segments if needed
                            var flat = (Array.isArray(coords[0]) && Array.isArray(coords[0][0])) ? coords.flat() : coords;
                            if (flat.length === 0) continue;
                            var info = nearestPointOnPolyline(user, flat);
                            if (!info) continue;
                            if (!bestInfo || info.dist < bestInfo.dist) {
                                bestInfo = info;
                                bestStreet = {name: st.name, coords: flat};
                            }
                        }

                        if (!bestStreet || !bestInfo) { alert("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É"); return; }

                        var nearPt = bestInfo.point;
                        var meters = Math.round(bestInfo.dist);
                        var walkMin = Math.max(1, Math.round((meters/1000)/5*60)); // 5 km/h

                        // –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
                        if (!window.__sperren_marks) window.__sperren_marks = [];
                        window.__sperren_marks.forEach(function(l){ try{ MAP.removeLayer(l); } catch(e){} });
                        window.__sperren_marks = [];

                        // flyTo –∏ –æ—Ç–∫—Ä—ã—Ç–∏–µ popup –ø–æ—Å–ª–µ –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Ç–∞–π–º–∞—É—Ç–∞, —á—Ç–æ–±—ã –∫–∞—Ä—Ç–∞ —É—Å–ø–µ–ª–∞ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è
                        MAP.flyTo(nearPt, 17);
                        setTimeout(function(){
                            var m = L.marker(nearPt).addTo(MAP);
                            m.bindPopup(
                                "<div style='font-family:Arial,Helvetica,sans-serif; font-size:14px;'><b>–ë–ª–∏–∂–∞–π—à–∞—è —É–ª–∏—Ü–∞:</b> " + (bestStreet.name || "‚Äî") +
                                "<br><b>–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ:</b> " + meters + " –º" +
                                "<br><b>–ü–µ—à–∫–æ–º:</b> –ø—Ä–∏–º–µ—Ä–Ω–æ " + walkMin + " –º–∏–Ω</div>"
                            ).openPopup();
                            window.__sperren_marks.push(m);
                        }, 600);

                        // –º–∞—Ä–∫–µ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ–º popup —á—Ç–æ–±—ã –Ω–µ –∑–∞–∫—Ä—ã—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π)
                        var um = L.circleMarker(user, {radius:6, color:'#333', fillColor:'#fff', weight:2}).addTo(MAP);
                        um.bindPopup("–í—ã –∑–¥–µ—Å—å");
                        window.__sperren_marks.push(um);

                    }, function(err) {
                        alert("–û—à–∏–±–∫–∞ –≥–µ–æ–ø–æ–∑–∏—Ü–∏–∏: " + err.message);
                    }, {enableHighAccuracy:true, timeout:10000, maximumAge:0});
                }

                // --- –ö–Ω–æ–ø–∫–∞ (—Å –Ω–µ–±–æ–ª—å—à–∏–º —Å—Ç–∏–ª–µ–º) ---
                var btn = document.createElement("button");
                btn.textContent = "–ü–æ–∫–∞–∑–∞—Ç—å –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É –∫–æ –º–Ω–µ";
                btn.style.position = "absolute";
                btn.style.top = "12px";
                btn.style.left = "50%";
                btn.style.transform = "translateX(-50%)";
                btn.style.zIndex = 1000;
                btn.style.padding = "8px 14px";
                btn.style.background = "#ffffff";
                btn.style.border = "1px solid rgba(0,0,0,0.15)";
                btn.style.borderRadius = "8px";
                btn.style.boxShadow = "0 2px 6px rgba(0,0,0,0.08)";
                btn.style.fontFamily = "Arial, Helvetica, sans-serif";
                btn.style.cursor = "pointer";
                btn.onclick = showNearestStreet;
                document.body.appendChild(btn);

                // ==== –ü–ª–∞–≤–∞—é—â–∏–π —Ä–µ–∫–ª–∞–º–Ω—ã–π –±–ª–æ–∫ (–∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –¥–∏–∑–∞–π–Ω) ====
                var adWrap = document.createElement("div");
                adWrap.id = "__sperren_ad";
                adWrap.style.position = "fixed";
                adWrap.style.bottom = "22px";
                adWrap.style.right = "22px";
                adWrap.style.zIndex = 99999;
                adWrap.style.width = "260px";
                adWrap.style.maxWidth = "calc(100% - 44px)";
                adWrap.style.boxSizing = "border-box";
                adWrap.style.fontFamily = "Inter, Arial, Helvetica, sans-serif";
                adWrap.style.transition = "transform 0.24s ease, opacity 0.2s ease";
                adWrap.style.boxShadow = "0 10px 30px rgba(0,0,0,0.12)";
                adWrap.style.borderRadius = "12px";
                adWrap.style.overflow = "hidden";
                adWrap.style.background = "linear-gradient(180deg,#ffffff,#fbfbff)";

                // inner content
                var adInner = document.createElement("div");
                adInner.style.padding = "12px";
                adInner.style.display = "flex";
                adInner.style.gap = "10px";
                adInner.style.alignItems = "center";

                // left: logo / icon
                var adIcon = document.createElement("div");
                adIcon.src = "https://routefromhome-collab.github.io/sperren-map/logo.jpg"; 
                adIcon.style.width = "48px";
                adIcon.style.height = "48px";
                adIcon.style.borderRadius = "10px";
                adIcon.style.flex = "0 0 48px";
                adIcon.style.objectFit = "cover";
                adIcon.style.display = "flex";
                adIcon.style.alignItems = "center";
                adIcon.style.justifyContent = "center";
                
                adIcon.style.color = "#fff";
                adIcon.style.fontWeight = "700";
                adIcon.style.fontSize = "20px";
                

                // center: text
                var adTextWrap = document.createElement("div");
                adTextWrap.style.flex = "1 1 auto";
                adTextWrap.innerHTML = "<div style='font-size:15px; font-weight:700; color:#111; line-height:1.05;'>‚ö° –ö–∞—Ä—Ç–∞ –æ—Ç Schwebezeit</div>" +
                                       "<div style='font-size:13px; color:#444; margin-top:4px;'>–õ—É—á—à–∏–π –∫–∞–Ω–∞–ª ‚Äî –ø–æ–¥–ø–∏—à–∏—Å—å –≤ Telegram</div>";

                // right: CTA
                var adCTA = document.createElement("div");
                adCTA.style.flex = "0 0 auto";
                var ctaBtn = document.createElement("button");
                ctaBtn.textContent = "–ü–µ—Ä–µ–π—Ç–∏";
                ctaBtn.style.background = "#1d72ff";
                ctaBtn.style.color = "#fff";
                ctaBtn.style.border = "none";
                ctaBtn.style.padding = "8px 10px";
                ctaBtn.style.borderRadius = "8px";
                ctaBtn.style.cursor = "pointer";
                ctaBtn.style.fontWeight = "700";
                ctaBtn.onclick = function(e){ e.stopPropagation(); window.open('https://t.me/schwebezeit','_blank'); };
                adCTA.appendChild(ctaBtn);

                adInner.appendChild(adIcon);
                adInner.appendChild(adTextWrap);
                adInner.appendChild(adCTA);

                // top-right close button
                var closeBtn = document.createElement("button");
                closeBtn.innerHTML = "‚úï";
                closeBtn.style.position = "absolute";
                closeBtn.style.top = "6px";
                closeBtn.style.right = "8px";
                closeBtn.style.width = "28px";
                closeBtn.style.height = "28px";
                closeBtn.style.border = "none";
                closeBtn.style.background = "transparent";
                closeBtn.style.color = "#666";
                closeBtn.style.cursor = "pointer";
                closeBtn.style.fontSize = "14px";
                closeBtn.onclick = function(e){ e.stopPropagation(); adWrap.style.transform = 'translateY(16px) scale(0.98)'; adWrap.style.opacity='0'; setTimeout(function(){ try{ adWrap.remove(); }catch(e){} },220); };

                adWrap.appendChild(adInner);
                adWrap.appendChild(closeBtn);

                // small footer (powered by)
                var adFooter = document.createElement("div");
                adFooter.style.padding = "8px 12px";
                adFooter.style.fontSize = "11px";
                adFooter.style.color = "#666";
                adFooter.style.background = "rgba(0,0,0,0.02)";
                adFooter.style.textAlign = "center";
                adFooter.innerHTML = "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ ‚Äî <a href='https://t.me/schwebezeit' target='_blank' style='color:#1d72ff;text-decoration:none;'>Schwebezeit</a>";
                adFooter.onclick = function(e){ e.stopPropagation(); window.open('https://t.me/schwebezeit','_blank'); };

                // append footer to wrap
                adWrap.appendChild(adFooter);

                // click on whole card opens channel
                adWrap.onclick = function(){ window.open('https://t.me/schwebezeit','_blank'); };

                document.body.appendChild(adWrap);
                // === end ad block ===

            } catch (err) {
                console.error("MAP script init error:", err);
            }
        });
        </script>
        """

    # –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –º–∞—Ä–∫–µ—Ä–æ–≤: —Å–Ω–∞—á–∞–ª–∞ MAP (–µ—Å–ª–∏ map_var –Ω–∞–π–¥–µ–Ω) ‚Äî –≤—Å—Ç–∞–≤–ª—è–µ–º JS-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ, –∏–Ω–∞—á–µ null
    map_token = map_var if map_var else "null"
    # STREETS –≤—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É, –∏–Ω–∞—á–µ JSON –≤–Ω—É—Ç—Ä–∏ JS –º–æ–∂–µ—Ç —Å–ª–æ–º–∞—Ç—å HTML
    streets_token = streets_json.replace("'", "\\'").replace("\n", "\\n")

    inject_js = js_template.replace("<<<MAP>>>",
                                    map_token).replace("<<<STREETS>>>",
                                                       streets_token)

    # –≤—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ </body>
    if "</body>" in html_text:
        html_text = html_text.replace("</body>", inject_js + "</body>")
    else:
        html_text = html_text + inject_js

    with open(filename, "w", encoding="utf-8") as fh:
        fh.write(html_text)

    # push to GitHub Pages –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Ç–æ–∫–µ–Ω
    if not os.getenv("GITHUB_TOKEN"):
        logger.info("NO GITHUB_TOKEN ‚Äî saved locally: %s", filename)
        return filename

    TOKEN = os.getenv("GITHUB_TOKEN")
    REPO = "routefromhome-collab/sperren-map"
    BRANCH = "main"
    repo_url = f"https://{TOKEN}@github.com/{REPO}.git"

    try:
        subprocess.run(
            ["git", "config", "--global", "user.email", "bot@example.com"],
            check=False)
        subprocess.run(["git", "config", "--global", "user.name", "MapBot"],
                       check=False)
        subprocess.run(
            ["git", "pull", "--rebase", "--autostash", repo_url, BRANCH],
            check=False)
        subprocess.run(["git", "add", "."], check=False)
        subprocess.run([
            "git", "commit", "-m", f"Update map {datetime.now().isoformat()}"
        ],
                       check=False)
        subprocess.run(["git", "push", repo_url, BRANCH], check=False)
    except Exception as e:
        logger.warning("Git push failed: %s", e)

    public_url = f"https://routefromhome-collab.github.io/sperren-map/{filename}"
    logger.info("Map available: %s", public_url)
    return public_url


# ------- –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ -------
async def start_parsing(application: Application):
    bot = application.bot

    target_date = datetime.strptime("1 December 2025", "%d %B %Y")
    month_translation = {
        "January": "Januar",
        "February": "Februar",
        "March": "M√§rz",
        "April": "April",
        "May": "Mai",
        "June": "Juni",
        "July": "Juli",
        "August": "August",
        "September": "September",
        "October": "Oktober",
        "November": "November",
        "December": "Dezember"
    }

    # read streets
    streets_df = pd.read_excel('2.xlsx', engine='openpyxl')
    streets = streets_df["STRNAME"].str.rstrip('.').to_list()
    #streets = ["Bachstr"]
    city = "Wuppertal"
    url = 'https://awg-wuppertal.de/privatkunden/abfallkalender.html'

    cache = load_cache()
    rate_limiter = RateLimiter(RATE_LIMIT_DELAY)
    connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT_REQUESTS)
    timeout = aiohttp.ClientTimeout(total=60)

    async with aiohttp.ClientSession(connector=connector,
                                     timeout=timeout) as session:
        text = await safe_request(session, "GET", url, rate_limiter)
        if not text:
            await tg_send(bot,
                          chat_id=CHAT_ID,
                          text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ñ–æ—Ä–º–æ–π.")
            return

        soup = BeautifulSoup(text, 'lxml')
        form = soup.find('form', attrs={'name': 'demand'})
        if not form:
            await tg_send(bot, chat_id=CHAT_ID, text="‚ùå –§–æ—Ä–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return

        post_url = urljoin(url, form.get('action'))
        data_template = {
            i.get('name'): i.get('value') or ''
            for i in form.find_all('input')
        }
        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

        days_ahead = 7
        for day_offset in range(days_ahead):
            current_date = target_date + timedelta(days=day_offset)
            current_day = current_date.strftime("%d").lstrip('0')
            current_month = f"{month_translation[current_date.strftime('%B')]} {current_date.strftime('%Y')}"
            previous_date = current_date - timedelta(days=1)
            previous_day = previous_date.strftime("%d").lstrip('0')
            previous_month = f"{month_translation[previous_date.strftime('%B')]} {previous_date.strftime('%Y')}"

            # —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç–∞
            await tg_send(
                bot,
                chat_id=CHAT_ID,
                text=f"üîç –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ {previous_day} {previous_month}...")

            # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á
            tasks = []
            for street in streets:
                dcopy = data_template.copy()
                dcopy['tx_bwwastecalendar_pi1[demand][streetname]'] = street
                tasks.append(
                    fetch_and_parse(session, post_url, dcopy, street,
                                    current_month, current_day, semaphore,
                                    cache, rate_limiter))

            # –ø—Ä–æ–≥—Ä–µ—Å—Å: —Å–æ–∑–¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            progress_message = None
            try:
                progress_message = await bot.send_message(
                    chat_id=CHAT_ID, text=f"–ü—Ä–æ–≥—Ä–µ—Å—Å: 0/{len(tasks)} —É–ª–∏—Ü...")
            except Exception:
                progress_message = None

            results = []
            idx = 0
            with tqdm(total=len(tasks),
                      desc=f"–ü–∞—Ä—Å–∏–Ω–≥ {previous_day} {previous_month}",
                      unit="—É–ª–∏—Ü") as pbar:
                # –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                for coro in tqdm_asyncio.as_completed(tasks, total=len(tasks)):
                    res = await coro
                    results.append(res)
                    idx += 1
                    pbar.update(1)
                    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ telegram –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ä–∞–∑ –≤ PROGRESS_UPDATE_EVERY
                    if progress_message and (idx % PROGRESS_UPDATE_EVERY == 0
                                             or idx == len(tasks)):
                        try:
                            await progress_message.edit_text(
                                f"üîç –ü–∞—Ä—Å–∏–Ω–≥ {previous_day} {previous_month}\n–ü—Ä–æ–≥—Ä–µ—Å—Å: {idx}/{len(tasks)} —É–ª–∏—Ü"
                            )
                        except RetryAfter as e:
                            await asyncio.sleep(e.retry_after + 1)
                        except Exception:
                            pass

            # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            flattened = []
            for r in results:
                if isinstance(r, list):
                    flattened.extend(r)
                elif isinstance(r, str):
                    flattened.append(r)
            unique_addresses = list(filter(None, flattened))

            # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —É–ª–∏—Ü–∞–º (–∫–ª—é—á–∏ ‚Äî –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —É–ª–∏—Ü)
            grouped = group_addresses_by_street(unique_addresses)
            streets_only = sorted(grouped.keys())

            if streets_only:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç (HTML)
                lines = [f"üóë <b>–®–ø–µ—Ä–∞ {previous_day} {previous_month}:</b>\n"]
                for street_name in streets_only:
                    # –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è (—ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML)
                    display = html.escape(street_name)
                    search_url = f"https://www.google.com/maps/search/?api=1&query={quote(f'{street_name}, {city}')}"
                    # HTML link: <a href="url">text</a>
                    lines.append(f'{display} <a href="{search_url}">map</a>')

                # –º–∞—Ä—à—Ä—É—Ç—ã –ø–æ —É–ª–∏—Ü–∞–º (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 20 —É–ª–∏—Ü)
                ordered, route_urls, coords_map = build_optimal_route(
                    streets_only, city=city)

                for i, route_url in enumerate(route_urls, start=1):
                    # –≤—Å—Ç–∞–≤–ª—è–µ–º –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å –ø–æ–º–µ—Ç–∫–æ–π "map (URL)"
                    # –≤ HTML: –¥–µ–ª–∞–µ–º –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É
                    lines.append(
                        f'\nüó∫ –ú–∞—Ä—à—Ä—É—Ç (—á–∞—Å—Ç—å {i}): <a href="{route_url}">map</a>'
                    )

                # —Å–æ–∑–¥–∞—ë–º –∫–∞—Ä—Ç—É —Å–æ –≤—Å–µ–º–∏ –∞–¥—Ä–µ—Å–∞–º–∏ (–≤–∫–ª—é—á–∞—è –¥–æ–º–∞) –∏ –ø—É—à–∏–º
                filename = f"map_{previous_day}_{previous_month.replace(' ', '_')}.html"
                gh_url = create_map_and_push(unique_addresses, city, filename)

                # –¥–æ–±–∞–≤–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ GH Pages
                if gh_url:
                    lines.append(
                        f'\nüìç–ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞ {previous_day} {previous_month}: <a href="{gh_url}">map</a>'
                    )

                # —Ö—ç—à—Ç–µ–≥ –≤ –∫–æ–Ω—Ü–µ
                lines.append("\n#—à–ø–µ—Ä–∞")

                full_text = "\n".join(lines)
                # —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –∏ –æ—Ç—Å—ã–ª–∞–µ–º (HTML)
                chunks = chunk_text(full_text, max_len=TELEGRAM_CHUNK_MAX)

                for chunk in chunks:
                    await tg_send(bot,
                                  chat_id=CHAT_ID,
                                  text=chunk,
                                  parse_mode="HTML",
                                  disable_web_page_preview=True)
                    await asyncio.sleep(0.3)  # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞

            else:
                await tg_send(
                    bot,
                    chat_id=CHAT_ID,
                    text=
                    f"‚úÖ {previous_day} {previous_month} –≤—ã—Ö–æ–¥–Ω–æ–π.\n\n#—à–ø–µ—Ä–∞")

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
            save_cache(cache)


# ------- main -------
async def main():
    if not TELEGRAM_BOT_TOKEN or not CHAT_ID:
        logger.error("TELEGRAM_BOT_TOKEN or CHAT_ID not set")
        sys.exit(1)
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    await start_parsing(application)


if __name__ == '__main__':

    # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    if os.path.exists("addresses.json"):
        try:
            with open("addresses.json", "r", encoding="utf-8") as f:
                data = json.load(f)

            city = data.get("city", "")
            addresses = data.get("addresses", [])

            if addresses:
                print(
                    "üìå –ù–∞–π–¥–µ–Ω addresses.json ‚Äî —Å–æ–∑–¥–∞—ë–º –∫–∞—Ä—Ç—É –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞..."
                )
                result = create_map_and_push(addresses, city, "debug_map.html")
                print("‚úÖ –ö–∞—Ä—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞:", result)
                sys.exit()  # ‚úÖ –≤—ã—Ö–æ–¥–∏–º, main() –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
            else:
                print("‚ö†Ô∏è –í addresses.json –Ω–µ—Ç –ø–æ–ª—è addresses")

        except Exception as e:
            print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è addresses.json:", e)

    # ‚úÖ –µ—Å–ª–∏ –∞–¥—Ä–µ—Å–æ–≤ –Ω–µ—Ç ‚Äî –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    asyncio.run(main())
