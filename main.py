import aiohttp
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote
import pandas as pd
from telegram.ext import Application
from datetime import datetime, timedelta
import re
import os
import sys
import json
import random
from collections import defaultdict
import time
from tqdm.asyncio import tqdm_asyncio
from tqdm import tqdm
import subprocess
import folium
from geopy.geocoders import Nominatim
import logging
from telegram.error import RetryAfter, TelegramError
import html
import math
from geopy.extra.rate_limiter import RateLimiter as GeoRateLimiter
# ------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏/–∫–æ–Ω—Ñ–∏–≥ -------
print(os.getcwd())

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')  # GitHub PAT (optional)
CACHE_FILE = 'cache.json'

MAX_CONCURRENT_REQUESTS = 60  # –º–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å/–ø–æ–Ω–∏–∑–∏—Ç—å
RATE_LIMIT_DELAY = 0.01
PROGRESS_UPDATE_EVERY = 50  # –æ–±–Ω–æ–≤–ª—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ç–µ–ª–µ–≥–µ –∫–∞–∂–¥—ã–µ N —É–ª–∏—Ü
TELEGRAM_CHUNK_MAX = 4000  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è

GEOCODE_TIMEOUT = 10
USER_AGENT = "sperren_route_optimizer"
MAX_POINTS = 300  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –ø–æ —É—Å–ª–æ–≤–∏—é
GOOGLE_CHUNK = 20  # Google Maps waypoints per link


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def haversine_km(a, b):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º) –º–µ–∂–¥—É –ø–∞—Ä–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç a=(lat,lon), b=(lat,lon)."""
    lat1, lon1 = math.radians(a[0]), math.radians(a[1])
    lat2, lon2 = math.radians(b[0]), math.radians(b[1])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    R = 6371.0088
    sa = math.sin(
        dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2
    return 2 * R * math.asin(math.sqrt(sa))


def geocode_addresses(addresses, city=None, pause=1.0):
    """
        –ì–µ–æ–∫–æ–¥–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {address: (lat,lon)}.
        - addresses: —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–º–æ–∂–Ω–æ –¥–æ 300)
        - city: –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –∑–∞–ø—Ä–æ—Å—É (–Ω–∞–ø—Ä–∏–º–µ—Ä 'Wuppertal')
        - pause: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ Nominatim
        """
    geolocator = Nominatim(user_agent=USER_AGENT,
                           timeout=GEOCODE_TIMEOUT)  # type: ignore
    geocode = GeoRateLimiter(geolocator.geocode, min_delay_seconds=pause)

    coords = {}
    for addr in addresses:
        query = f"{addr}, {city}" if city else addr
        try:
            loc = geocode(query)
            if loc:
                coords[addr] = (loc.latitude, loc.longitude)
            else:
                coords[addr] = None
        except Exception as e:
            logger.warning("Geocode failed for '%s': %s", addr, e)
            coords[addr] = None

        # –Ω–µ–±–æ–ª—å—à–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è —É–≤–∞–∂–µ–Ω–∏—è Nominatim
        time.sleep(random.uniform(0.2, 0.6))

    return coords


def build_distance_matrix(coord_list):
    """coord_list: list of (lat,lon). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (km)."""
    n = len(coord_list)
    mat = [[0.0] * n for _ in range(n)]
    for i in range(n):
        for j in range(i + 1, n):
            d = haversine_km(coord_list[i], coord_list[j])
            mat[i][j] = d
            mat[j][i] = d
    return mat


# --- TSP: nearest neighbor + 2-opt ---
def nearest_neighbor_tsp(dist_mat, start_index=0):
    n = len(dist_mat)
    visited = [False] * n
    route = [start_index]
    visited[start_index] = True
    for _ in range(n - 1):
        last = route[-1]
        # –≤—ã–±—Ä–∞—Ç—å –±–ª–∏–∂–∞–π—à—É—é –Ω–µ –ø–æ—Å–µ—â—ë–Ω–Ω—É—é
        best = None
        bestd = float('inf')
        for j in range(n):
            if not visited[j] and dist_mat[last][j] < bestd:
                bestd = dist_mat[last][j]
                best = j
        if best is None:
            break
        route.append(best)
        visited[best] = True
    return route


def two_opt(route, dist_mat, improvement_threshold=0.0001):
    """
    –£–ª—É—á—à–µ–Ω–∏–µ 2-opt. route ‚Äî —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤.
    """
    n = len(route)
    if n < 4:
        return route
    improved = True
    while improved:
        improved = False
        for i in range(1, n - 2):
            for j in range(i + 1, n):
                if j - i == 1:  # —Å–æ—Å–µ–¥–Ω–∏–µ, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                    continue
                a, b = route[i - 1], route[i]
                c, d = route[j - 1], route[j % n]
                delta = dist_mat[a][c] + dist_mat[b][d] - dist_mat[a][
                    b] - dist_mat[c][d]
                if delta < -improvement_threshold:
                    # invert
                    route[i:j] = reversed(route[i:j])
                    improved = True
        # –º–æ–∂–Ω–æ –≤—ã–π—Ç–∏, –µ—Å–ª–∏ –Ω–µ —É–ª—É—á—à–∏–ª–æ—Å—å
    return route


USER_AGENTS = [
    # –Ω–µ—Å–∫–æ–ª—å–∫–æ user-agents –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
]

# –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ------- –£—Ç–∏–ª–∏—Ç—ã -------
def get_random_headers():
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept":
        "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "Connection": "keep-alive",
    }


def normalize_street_name(name: str) -> str:
    name = name.lower().strip()
    name = re.sub(r'\bstr\b\.?$', 'stra√üe', name)
    name = re.sub(r'str\.$', 'stra√üe', name)
    name = re.sub(r'str$', 'stra√üe', name)
    name = name.replace('strasse', 'stra√üe')
    return name


def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_cache(cache):
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


def chunk_text(text, max_len=TELEGRAM_CHUNK_MAX):
    chunks = []
    while len(text) > max_len:
        # try split at newline
        split_at = text.rfind('\n', 0, max_len)
        if split_at == -1:
            split_at = max_len
        chunks.append(text[:split_at])
        text = text[split_at:].lstrip('\n')
    if text:
        chunks.append(text)
    return chunks


def group_addresses_by_street(addresses):
    grouped = defaultdict(list)
    for addr in addresses:
        # –µ—Å–ª–∏ –∞–¥—Ä–µ—Å –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —á–∏—Å–ª–æ –∏–ª–∏ —á–∏—Å–ª–æ+–±—É–∫–≤—É ‚Üí –µ—Å—Ç—å –¥–æ–º
        m = re.match(r"^(.*?)[\s]+(\d+[a-zA-Z]?)$", addr.strip())
        if m:
            street = m.group(1).strip()
            house = m.group(2).strip()
            grouped[street].append(house)
        else:
            # –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏–µ —É–ª–∏—Ü—ã
            grouped[addr.strip()] = []

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–æ–º–∞–º –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
    def house_key(h):
        m = re.match(r"(\d+)(.*)", h)
        if m:
            return (int(m.group(1)), m.group(2))
        return (10**9, h)

    for s in grouped:
        grouped[s] = sorted(set(grouped[s]), key=house_key)

    return grouped


def generate_google_maps_route_links(ordered_addresses,
                                     city,
                                     chunk_size=GOOGLE_CHUNK):
    """
        ordered_addresses: list –∞–¥—Ä–µ—Å–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (—Å—Ç—Ä–æ–∫–∏)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ Google Maps; –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç <= chunk_size —Ç–æ—á–µ–∫.
        –§–æ—Ä–º–∞—Ç: https://www.google.com/maps/dir/{A}/{B}/{C}/
        (–∏—Å–ø–æ–ª—å–∑—É–µ–º url-encoded –∞–¥—Ä–µ—Å—ã)
        """
    links = []
    # Google –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç origin/destination/waypoints; –ø—Ä–æ—â–µ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /dir/A/B/C/...
    i = 0
    while i < len(ordered_addresses):
        segment = ordered_addresses[i:i + chunk_size]
        encoded = [quote(f"{s}, {city}") for s in segment]
        route_url = "https://www.google.com/maps/dir/" + "/".join(
            encoded) + "/"
        links.append(route_url)
        i += chunk_size
    return links


    # --- –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç ---
def build_optimal_route(addresses_with_houses,
                        start_coords=None,
                        city=None,
                        geocode_pause=1.0):
    """
        addresses_with_houses: —Å–ø–∏—Å–æ–∫ –ø–æ–ª–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ (—Å—Ç—Ä–æ–∫) ‚Äî —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å (–¥–æ 300).
        start_coords:
            - –µ—Å–ª–∏ tuple(lat,lon) ‚Äî –º–∞—Ä—à—Ä—É—Ç –Ω–∞—á–Ω—ë—Ç—Å—è –ò–ó —ç—Ç–æ–π —Ç–æ—á–∫–∏
            - –µ—Å–ª–∏ None ‚Äî –º–∞—Ä—à—Ä—É—Ç –Ω–∞—á–Ω—ë—Ç—Å—è –° –ü–ï–†–í–û–ô –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–æ—á–∫–∏
        city: –≥–æ—Ä–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä "Wuppertal")
        geocode_pause: –ø–∞—É–∑–∞ –º–µ–∂–¥—É –≥–µ–æ–∫–æ–¥–∞–º–∏
        """

    if len(addresses_with_houses) == 0:
        return [], [], {}

    if len(addresses_with_houses) > MAX_POINTS:
        raise ValueError(
            f"Too many points: {len(addresses_with_houses)} > {MAX_POINTS}")

    # 1) –ì–µ–æ–∫–æ–¥–∏—Ä—É–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞
    coords_map = geocode_addresses(addresses_with_houses,
                                   city=city,
                                   pause=geocode_pause)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –Ω–∞—à–ª–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    found_items = [a for a in addresses_with_houses if coords_map.get(a)]
    if not found_items:
        # –Ω–∏—á–µ–≥–æ –Ω–µ –≥–µ–æ–∫–æ–¥–∏—Ä—É–µ—Ç—Å—è ‚Äî –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        return addresses_with_houses, [], coords_map

    coord_list = [coords_map[a] for a in found_items]

    added_start = False
    start_index = 0

    # ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º:
    # –µ—Å–ª–∏ start_coords –µ—Å—Ç—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –Ω–∞—á–∞–ª–æ
    # –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π –∞–¥—Ä–µ—Å–Ω–æ–π —Ç–æ—á–∫–∏, –Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–º–∞–µ—Ç—Å—è
    if start_coords:
        coord_list = [start_coords] + coord_list
        found_items = ["__START__"] + found_items
        added_start = True
        start_index = 0
    else:
        start_index = 0  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞ —Å–ø–∏—Å–∫–∞

    # –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
    dist_mat = build_distance_matrix(coord_list)

    # –ë–∞–∑–æ–≤—ã–π TSP + —É–ª—É—á—à–µ–Ω–∏–µ
    initial_route = nearest_neighbor_tsp(dist_mat, start_index=start_index)
    improved = two_opt(initial_route[:], dist_mat)

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤
    ordered = [found_items[i] for i in improved]

    # –ï—Å–ª–∏ –±—ã–ª –ø—Å–µ–≤–¥–æ-—Å—Ç–∞—Ä—Ç __START__, —É–±–∏—Ä–∞–µ–º –º–µ—Ç–∫—É
    if added_start:
        if ordered and ordered[0] == "__START__":
            ordered = ordered[1:]

    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤
    final_addresses = []
    for a in ordered:
        if a != "__START__":
            final_addresses.append(a)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Google Maps —Å—Å—ã–ª–æ–∫
    route_links = []
    if start_coords:
        # —Å—Ç–∞—Ä—Ç ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        all_points = [f"{start_coords[0]},{start_coords[1]}"
                      ] + [f"{a}, {city}" for a in final_addresses]
        i = 0
        while i < len(all_points):
            seg = all_points[i:i + GOOGLE_CHUNK]
            encoded = [quote(s) for s in seg]
            route_links.append("https://www.google.com/maps/dir/" +
                               "/".join(encoded) + "/")
            i += GOOGLE_CHUNK
    else:
        # —Å—Ç–∞—Ä—Ç ‚Äî –ø–µ—Ä–≤–∞—è –∞–¥—Ä–µ—Å–Ω–∞—è —Ç–æ—á–∫–∞
        route_links = generate_google_maps_route_links(final_addresses,
                                                       city,
                                                       chunk_size=GOOGLE_CHUNK)

    return final_addresses, route_links, coords_map


# ------- Rate limiter –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å -------
class RateLimiter:

    def __init__(self, delay):
        self.delay = delay
        self.last_request = 0

    async def acquire(self):
        current = time.time()
        diff = current - self.last_request
        if diff < self.delay:
            await asyncio.sleep(self.delay - diff)
        self.last_request = time.time()


async def safe_request(session, method, url, rate_limiter, **kwargs):
    retries = 5
    for attempt in range(retries):
        try:
            await rate_limiter.acquire()
            headers = kwargs.pop('headers', None) or get_random_headers()
            async with session.request(method, url, headers=headers,
                                       **kwargs) as response:
                if response.status in (429, ) or response.status >= 500:
                    wait = min(2**attempt + random.random(), 30)
                    logger.warning("HTTP %s from %s ‚Äî wait %.1fs",
                                   response.status, url, wait)
                    await asyncio.sleep(wait)
                    continue
                return await response.text()
        except Exception as e:
            wait = min(2**attempt + random.random(), 30)
            logger.warning("Request error %s -> waiting %.1fs", e, wait)
            await asyncio.sleep(wait)
    logger.error("Failed to get %s after %d attempts", url, retries)
    return None


# ------- Telegram helper with RetryAfter handling (HTML parse_mode) -------
async def tg_send(bot, method='send_message', **kwargs):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞: –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç RetryAfter.
    method: 'send_message' or 'send_photo' etc. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é send_message.
    kwargs ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–∑–æ–≤–∞ –º–µ—Ç–æ–¥–∞.
    """
    max_attempts = 6
    for attempt in range(max_attempts):
        try:
            if method == 'send_message':
                return await bot.send_message(**kwargs)
            else:
                # –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                return await getattr(bot, method)(**kwargs)
        except RetryAfter as e:
            wait = e.retry_after + 1
            logger.warning("Telegram RetryAfter: wait %s s", wait)
            await asyncio.sleep(wait)
        except TelegramError as e:
            logger.warning("TelegramError: %s (attempt %d/%d)", e, attempt + 1,
                           max_attempts)
            await asyncio.sleep(min(2**attempt, 30))
        except Exception as e:
            logger.exception("Unexpected Telegram exception: %s", e)
            await asyncio.sleep(min(2**attempt, 30))
    logger.error("Failed to send telegram message after retries.")
    return None


# ------- –ü–∞—Ä—Å–µ—Ä –æ–¥–Ω–æ–π —É–ª–∏—Ü—ã -------
async def fetch_and_parse(session, url, data, street, current_month,
                          current_day, semaphore, cache, rate_limiter):
    async with semaphore:
        key = f"{street}__{current_month}__{current_day}"
        if key in cache:
            return cache[key]
        text = await safe_request(session,
                                  "POST",
                                  url,
                                  rate_limiter,
                                  data=data,
                                  timeout=aiohttp.ClientTimeout(total=25))
        if not text:
            cache[key] = None
            return None

        soup = BeautifulSoup(text, 'lxml')
        month_divs = soup.find_all('div', class_='month')
        page_text = soup.get_text(" ", strip=True)
        is_calendar = any(div.find('td') for div in month_divs)
        found_addresses = []

        # —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤—ã–±–æ—Ä–æ–º –¥–æ–º–æ–≤
        if "Auf dieser Stra√üe gibt es mehrere Abfallkalender" in page_text:
            house_links = soup.select('a[href*="streetname"]')
            for link in house_links:
                house_number = link.get_text(strip=True)
                if not house_number:
                    continue
                full_link = urljoin(url, link.get('href'))
                house_text = await safe_request(
                    session,
                    "GET",
                    full_link,
                    rate_limiter,
                    timeout=aiohttp.ClientTimeout(total=15))
                if not house_text:
                    continue
                house_soup = BeautifulSoup(house_text, 'lxml')
                for month_div in house_soup.find_all('div', class_='month'):
                    header = month_div.find(['h3', 'span'])
                    if not header:
                        continue
                    if header.get_text(strip=True) != current_month:
                        continue
                    for td in month_div.find_all(
                            'td', class_=['', 'holiday', 'exception']):
                        day_text = ''.join(re.findall(r'\d+', td.get_text()))
                        if day_text == current_day and td.find(
                                "i", title="Sperrm√ºll"):
                            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å "Street Name house"
                            found_addresses.append(f"{street} {house_number}")

        # –µ—Å–ª–∏ —Å—Ä–∞–∑—É –∫–∞–ª–µ–Ω–¥–∞—Ä—å –¥–ª—è –≤—Å–µ–π —É–ª–∏—Ü—ã
        elif is_calendar:
            for month_div in month_divs:
                header = month_div.find(['h3', 'span'])
                if not header:
                    continue
                if header.get_text(strip=True) != current_month:
                    continue
                for td in month_div.find_all(
                        'td', class_=['', 'holiday', 'exception']):
                    day_text = ''.join(re.findall(r'\d+', td.get_text()))
                    if day_text == current_day and td.find("i",
                                                           title="Sperrm√ºll"):
                        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–ª—É—é —É–ª–∏—Ü—É
                        found_addresses.append(street)

        cache[key] = found_addresses if found_addresses else None
        return cache[key]


# ------- –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã (–≤–∫–ª—é—á–∞–µ–º –í–°–ï –∞–¥—Ä–µ—Å–∞) –∏ –ø—É—à –≤ Git (–∞–∫–∫—É—Ä–∞—Ç–Ω–æ) -------


def create_map_and_push(addresses, city, filename="map.html"):
    """
            –°–æ–∑–¥–∞—ë—Ç –∫–∞—Ä—Ç—É:
              - –º–∞—Ä–∫–µ—Ä—ã –¥–æ–º–æ–≤
              - –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É –∫–æ –º–Ω–µ
              - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏ –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –ø–µ—à–∫–æ–º
              - –ø—É—à–∏—Ç –≤ GH Pages (–µ—Å–ª–∏ GITHUB_TOKEN)
        """
    import os
    import json
    import logging
    import subprocess
    import requests
    import folium
    from datetime import datetime
    from geopy.geocoders import Nominatim
    from geopy.extra.rate_limiter import RateLimiter
    from folium.plugins import LocateControl

    logger = logging.getLogger("MAP")
    logger.setLevel(logging.INFO)

    geolocator = Nominatim(user_agent="sperren_map_streets")
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    fmap = folium.Map(location=[51.2562, 7.1508], zoom_start=12)

    geocoded_points = []
    street_names = set()
    street_geometries = []

    import re
    for addr in addresses:
        if isinstance(addr, str):
            m = re.match(r"^(.*\D)\s+(\d[\dA-Za-z/-]*)\s*$", addr.strip())
            street = m.group(1).strip() if m else addr.strip()
            street_names.add(street)

    for addr in addresses:
        try:
            q = f"{addr}, {city}" if city else addr
            loc = geocode(q)
            if not loc:
                continue
            lat, lon = float(loc.latitude), float(loc.longitude)
            geocoded_points.append([lat, lon])
            folium.Marker([lat, lon], popup=addr).add_to(fmap)
        except:
            continue

    if geocoded_points:
        fmap.fit_bounds(geocoded_points)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —É–ª–∏—Ü
    def overpass_query_for_street(name, city, timeout=25):
        q = f"""
                [out:json][timeout:{timeout}];
                area["name"="{city}"]->.a;
                (
                  way["name"="{name}"](area.a);
                  relation["name"="{name}"](area.a);
                );
                out geom;
                """
        try:
            r = requests.post("https://overpass-api.de/api/interpreter",
                              data=q.encode("utf-8"),
                              timeout=timeout)
            if r.status_code == 200:
                return r.json()
        except:
            pass
        return None

    # –ü–æ–ª—É—á–∞–µ–º –≥–µ–æ–º–µ—Ç—Ä–∏—é —É–ª–∏—Ü, –Ω–æ –ù–ï —Ä–∏—Å—É–µ–º –∏—Ö
    for street in sorted(street_names):
        try:
            data = overpass_query_for_street(street, city)
            coords_collected = []

            if data and data.get("elements"):
                for e in data["elements"]:
                    geom = e.get("geometry")
                    if not geom:
                        continue
                    seg = [[p["lat"], p["lon"]] for p in geom]
                    if seg:
                        coords_collected.append(seg)

            if coords_collected:
                mid = coords_collected[0][len(coords_collected[0]) // 2]
                street_geometries.append({
                    "name": street,
                    "coords": coords_collected[0],
                    "mid": mid
                })
                continue

            loc = geolocator.geocode({"street": street, "city": city})
            if loc:
                lat, lon = float(loc.latitude), float(loc.longitude)
                d = 0.00035
                seg = [[lat - d, lon - d], [lat + d, lon + d]]
                street_geometries.append({
                    "name": street,
                    "coords": seg,
                    "mid": [lat, lon]
                })

        except:
            pass

    if geocoded_points and not street_geometries:
        for p in geocoded_points:
            street_geometries.append({
                "name": "point",
                "coords": [p],
                "mid": p
            })

    try:
        LocateControl(auto_start=False).add_to(fmap)
    except:
        pass

    fmap.save(filename)

    with open(filename, "r", encoding="utf-8") as f:
        html = f.read()

    import re
    map_var = re.findall(r"var (\w+) = L\.map", html)
    map_var = map_var[0] if map_var else "map"

    js_streets = []
    for s in street_geometries:
        arr = s["coords"]
        js_streets.append({"name": s["name"], "coords": arr, "mid": s["mid"]})

    # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ä–∞—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –ø–µ—à–∫–æ–º
    inject_js = f"""
        <script>
        document.addEventListener("DOMContentLoaded", function() {{
            window.MAP = {map_var};
            var STREETS = {json.dumps(js_streets)};

            function meterDist(a,b){{
                var R = 6371000;
                var lat1=a[0]*Math.PI/180, lat2=b[0]*Math.PI/180;
                var dLat=(b[0]-a[0])*Math.PI/180, dLon=(b[1]-a[1])*Math.PI/180;
                var s=Math.sin(dLat/2)**2 + Math.cos(lat1)*Math.cos(lat2)*Math.sin(dLon/2)**2;
                return 2*R*Math.atan2(Math.sqrt(s), Math.sqrt(1-s));
            }}

            function showNearestStreet() {{
                if(!navigator.geolocation) return alert("–ì–µ–æ–ª–æ–∫–∞—Ü–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è");
                navigator.geolocation.getCurrentPosition(function(pos){{
                    var user=[pos.coords.latitude, pos.coords.longitude];
                    var best=null, bestDist=Infinity;

                    STREETS.forEach(s => {{
                        if(!s.mid) return;
                        var d=meterDist(user, s.mid);
                        if(d<bestDist) {{ bestDist=d; best=s; }}
                    }});

                    if(!best) return alert("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É");

                    // ‚úÖ –í—Ä–µ–º—è –ø–µ—à–∫–æ–º
                    var walkTimeSec = bestDist / 1.4;
                    var walkMin = Math.max(1, Math.round(walkTimeSec / 60));

                    L.marker(best.mid).addTo(MAP).bindPopup(
                        "–£–ª–∏—Ü–∞: <b>"+best.name+
                        "</b><br>–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ: "+Math.round(bestDist)+" –º"+
                        "<br>–ü–µ—à–∫–æ–º –ø—Ä–∏–º–µ—Ä–Ω–æ: "+walkMin+" –º–∏–Ω."
                    ).openPopup();

                    L.circleMarker(user, {{radius:6,color:'#000',fillColor:'#fff',weight:2}}).addTo(MAP).bindPopup("–í—ã –∑–¥–µ—Å—å");
                    MAP.flyTo(best.mid, 16);
                }}, err => alert("–û—à–∏–±–∫–∞ –≥–µ–æ–ø–æ–∑–∏—Ü–∏–∏: "+err.message), {{enableHighAccuracy:true}});
            }}

            var b=document.createElement("button");
            b.textContent="–ü–æ–∫–∞–∑–∞—Ç—å –±–ª–∏–∂–∞–π—à—É—é —É–ª–∏—Ü—É –∫–æ –º–Ω–µ";
            b.style.position="absolute"; b.style.top="10px"; b.style.left="50%";
            b.style.transform="translateX(-50%)";
            b.style.zIndex=999999; b.style.padding="8px 12px";
            b.style.background="white"; b.style.border="1px solid #666";
            b.style.borderRadius="6px";
            b.onclick=showNearestStreet;
            document.body.appendChild(b);
        }});
        </script>
        </body>
        """

    html = html.replace("</body>", inject_js)
    with open(filename, "w", encoding="utf-8") as f:
        f.write(html)

    # GitHub push
    if not os.getenv("GITHUB_TOKEN"):
        print("–ö–∞—Ä—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ:", filename)
        return filename

    TOKEN = os.getenv("GITHUB_TOKEN")
    REPO = "routefromhome-collab/sperren-map"
    BRANCH = "main"
    repo_url = f"https://{TOKEN}@github.com/{REPO}.git"

    try:
        subprocess.run(
            ["git", "config", "--global", "user.email", "bot@example.com"])
        subprocess.run(["git", "config", "--global", "user.name", "MapBot"])
        subprocess.run(
            ["git", "pull", "--rebase", "--autostash", repo_url, BRANCH])
        subprocess.run(["git", "add", filename])
        subprocess.run([
            "git", "commit", "-m", f"Update map {datetime.now().isoformat()}"
        ])
        subprocess.run(["git", "push", repo_url, BRANCH])
    except Exception as e:
        print("Git push failed:", e)

    url = f"https://routefromhome-collab.github.io/sperren-map/{filename}"
    print("Map available:", url)
    return url


# ------- –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ -------
async def start_parsing(application: Application):
    bot = application.bot

    target_date = datetime.strptime("18 November 2025", "%d %B %Y")
    month_translation = {
        "January": "Januar",
        "February": "Februar",
        "March": "M√§rz",
        "April": "April",
        "May": "Mai",
        "June": "Juni",
        "July": "Juli",
        "August": "August",
        "September": "September",
        "October": "Oktober",
        "November": "November",
        "December": "Dezember"
    }

    # read streets
    streets_df = pd.read_excel('2.xlsx', engine='openpyxl')
    streets = streets_df["STRNAME"].str.rstrip('.').to_list()
    city = "Wuppertal"
    url = 'https://awg-wuppertal.de/privatkunden/abfallkalender.html'

    cache = load_cache()
    rate_limiter = RateLimiter(RATE_LIMIT_DELAY)
    connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT_REQUESTS)
    timeout = aiohttp.ClientTimeout(total=60)

    async with aiohttp.ClientSession(connector=connector,
                                     timeout=timeout) as session:
        text = await safe_request(session, "GET", url, rate_limiter)
        if not text:
            await tg_send(bot,
                          chat_id=CHAT_ID,
                          text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ñ–æ—Ä–º–æ–π.")
            return

        soup = BeautifulSoup(text, 'lxml')
        form = soup.find('form', attrs={'name': 'demand'})
        if not form:
            await tg_send(bot, chat_id=CHAT_ID, text="‚ùå –§–æ—Ä–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return

        post_url = urljoin(url, form.get('action'))
        data_template = {
            i.get('name'): i.get('value') or ''
            for i in form.find_all('input')
        }
        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

        days_ahead = 7
        for day_offset in range(days_ahead):
            current_date = target_date + timedelta(days=day_offset)
            current_day = current_date.strftime("%d").lstrip('0')
            current_month = f"{month_translation[current_date.strftime('%B')]} {current_date.strftime('%Y')}"
            previous_date = current_date - timedelta(days=1)
            previous_day = previous_date.strftime("%d").lstrip('0')
            previous_month = f"{month_translation[previous_date.strftime('%B')]} {previous_date.strftime('%Y')}"

            # —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç–∞
            await tg_send(
                bot,
                chat_id=CHAT_ID,
                text=f"üîç –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ {previous_day} {previous_month}...")

            # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á
            tasks = []
            for street in streets:
                dcopy = data_template.copy()
                dcopy['tx_bwwastecalendar_pi1[demand][streetname]'] = street
                tasks.append(
                    fetch_and_parse(session, post_url, dcopy, street,
                                    current_month, current_day, semaphore,
                                    cache, rate_limiter))

            # –ø—Ä–æ–≥—Ä–µ—Å—Å: —Å–æ–∑–¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            progress_message = None
            try:
                progress_message = await bot.send_message(
                    chat_id=CHAT_ID, text=f"–ü—Ä–æ–≥—Ä–µ—Å—Å: 0/{len(tasks)} —É–ª–∏—Ü...")
            except Exception:
                progress_message = None

            results = []
            idx = 0
            with tqdm(total=len(tasks),
                      desc=f"–ü–∞—Ä—Å–∏–Ω–≥ {previous_day} {previous_month}",
                      unit="—É–ª–∏—Ü") as pbar:
                # –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                for coro in tqdm_asyncio.as_completed(tasks, total=len(tasks)):
                    res = await coro
                    results.append(res)
                    idx += 1
                    pbar.update(1)
                    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ telegram –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ä–∞–∑ –≤ PROGRESS_UPDATE_EVERY
                    if progress_message and (idx % PROGRESS_UPDATE_EVERY == 0
                                             or idx == len(tasks)):
                        try:
                            await progress_message.edit_text(
                                f"üîç –ü–∞—Ä—Å–∏–Ω–≥ {previous_day} {previous_month}\n–ü—Ä–æ–≥—Ä–µ—Å—Å: {idx}/{len(tasks)} —É–ª–∏—Ü"
                            )
                        except RetryAfter as e:
                            await asyncio.sleep(e.retry_after + 1)
                        except Exception:
                            pass

            # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            flattened = []
            for r in results:
                if isinstance(r, list):
                    flattened.extend(r)
                elif isinstance(r, str):
                    flattened.append(r)
            unique_addresses = list(filter(None, flattened))

            # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —É–ª–∏—Ü–∞–º (–∫–ª—é—á–∏ ‚Äî –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —É–ª–∏—Ü)
            grouped = group_addresses_by_street(unique_addresses)
            streets_only = sorted(grouped.keys())

            if streets_only:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç (HTML)
                lines = [f"üóë <b>–®–ø–µ—Ä–∞ {previous_day} {previous_month}:</b>\n"]
                for street_name in streets_only:
                    # –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è (—ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML)
                    display = html.escape(street_name)
                    search_url = f"https://www.google.com/maps/search/?api=1&query={quote(f'{street_name}, {city}')}"
                    # HTML link: <a href="url">text</a>
                    lines.append(f'{display} <a href="{search_url}">map</a>')

                # –º–∞—Ä—à—Ä—É—Ç—ã –ø–æ —É–ª–∏—Ü–∞–º (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 20 —É–ª–∏—Ü)
                ordered, route_urls, coords_map = build_optimal_route(
                    streets_only, city=city)

                for i, route_url in enumerate(route_urls, start=1):
                    # –≤—Å—Ç–∞–≤–ª—è–µ–º –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å –ø–æ–º–µ—Ç–∫–æ–π "map (URL)"
                    # –≤ HTML: –¥–µ–ª–∞–µ–º –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É
                    lines.append(
                        f'\nüó∫ –ú–∞—Ä—à—Ä—É—Ç (—á–∞—Å—Ç—å {i}): <a href="{route_url}">map</a>'
                    )

                # —Å–æ–∑–¥–∞—ë–º –∫–∞—Ä—Ç—É —Å–æ –≤—Å–µ–º–∏ –∞–¥—Ä–µ—Å–∞–º–∏ (–≤–∫–ª—é—á–∞—è –¥–æ–º–∞) –∏ –ø—É—à–∏–º
                filename = f"map_{previous_day}_{previous_month.replace(' ', '_')}.html"
                gh_url = create_map_and_push(unique_addresses, city, filename)

                # –¥–æ–±–∞–≤–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ GH Pages
                if gh_url:
                    lines.append(
                        f'\nüìç–ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ –Ω–∞ {previous_day} {previous_month}: <a href="{gh_url}">map</a>'
                    )

                # —Ö—ç—à—Ç–µ–≥ –≤ –∫–æ–Ω—Ü–µ
                lines.append("\n#—à–ø–µ—Ä–∞")

                full_text = "\n".join(lines)
                # —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –∏ –æ—Ç—Å—ã–ª–∞–µ–º (HTML)
                chunks = chunk_text(full_text, max_len=TELEGRAM_CHUNK_MAX)

                for chunk in chunks:
                    await tg_send(bot,
                                  chat_id=CHAT_ID,
                                  text=chunk,
                                  parse_mode="HTML",
                                  disable_web_page_preview=True)
                    await asyncio.sleep(0.3)  # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞

            else:
                await tg_send(
                    bot,
                    chat_id=CHAT_ID,
                    text=
                    f"‚úÖ {previous_day} {previous_month} –≤—ã—Ö–æ–¥–Ω–æ–π.\n\n#—à–ø–µ—Ä–∞")

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
            save_cache(cache)


# ------- main -------
async def main():
    if not TELEGRAM_BOT_TOKEN or not CHAT_ID:
        logger.error("TELEGRAM_BOT_TOKEN or CHAT_ID not set")
        sys.exit(1)
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    await start_parsing(application)


if __name__ == '__main__':
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())
